{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print classifier result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf, name):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "    \n",
    "    joblib.dump(clf, 'models/' + name + '.pkl') \n",
    "    \n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "        print()\n",
    "    \n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,\n",
    "                                        target_names=target_names))\n",
    "\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    results.append([clf_descr, score, train_time, test_time])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 13.782MB (training set)\n",
      "7532 documents - 8.262MB (test set)\n",
      "\n",
      "categories:  ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "categories = None\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "    \n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "target_names = data_train.target_names\n",
    "joblib.dump(target_names, 'categories.pkl') \n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print()\n",
    "\n",
    "print(\"categories: \", target_names)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 11314, n_features: 101322\n",
      "\n",
      "n_samples: 7532, n_features: 101322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.101s\n",
      "test time:  0.020s\n",
      "accuracy:   0.696\n",
      "dimensionality: 101322\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.56      0.43      0.49       319\n",
      "           comp.graphics       0.65      0.71      0.68       389\n",
      " comp.os.ms-windows.misc       0.75      0.46      0.57       394\n",
      "comp.sys.ibm.pc.hardware       0.59      0.72      0.65       392\n",
      "   comp.sys.mac.hardware       0.71      0.69      0.70       385\n",
      "          comp.windows.x       0.79      0.75      0.77       395\n",
      "            misc.forsale       0.81      0.72      0.76       390\n",
      "               rec.autos       0.76      0.72      0.74       396\n",
      "         rec.motorcycles       0.76      0.73      0.74       398\n",
      "      rec.sport.baseball       0.94      0.81      0.87       397\n",
      "        rec.sport.hockey       0.59      0.93      0.72       399\n",
      "               sci.crypt       0.72      0.76      0.74       396\n",
      "         sci.electronics       0.74      0.60      0.66       393\n",
      "                 sci.med       0.84      0.77      0.80       396\n",
      "               sci.space       0.75      0.80      0.78       394\n",
      "  soc.religion.christian       0.59      0.86      0.70       398\n",
      "      talk.politics.guns       0.56      0.72      0.63       364\n",
      "   talk.politics.mideast       0.81      0.80      0.80       376\n",
      "      talk.politics.misc       0.56      0.44      0.49       310\n",
      "      talk.religion.misc       0.47      0.21      0.29       251\n",
      "\n",
      "             avg / total       0.70      0.70      0.69      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[138   1   2   2   2   2   0   3   3   2  12   3   0   3  10  74  13  12\n",
      "   12  25]\n",
      " [  2 278   6  17  15  24   6   0   5   3   6  13   2   0   9   2   0   1\n",
      "    0   0]\n",
      " [  4  30 181  73  16  30   4   2   5   0  16  12   3   2   8   1   0   1\n",
      "    3   3]\n",
      " [  0  13  20 284  29   4  10   2   0   0   8   5  16   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0  11   8  32 265   5   8   7   2   0  14   7  13   2   6   2   1   1\n",
      "    1   0]\n",
      " [  0  46   9   9   7 297   1   0   0   1   7   5   5   3   4   0   1   0\n",
      "    0   0]\n",
      " [  1   4   1  32  18   0 281  14   7   3  11   1   7   2   4   1   1   0\n",
      "    2   0]\n",
      " [  1   1   1   1   1   0   9 285  31   1  25   4  10   1   6   3   4   3\n",
      "    9   0]\n",
      " [  8   3   1   0   2   3   7  26 290   1  15   0   8   3   6   3  11   3\n",
      "    7   1]\n",
      " [  5   2   0   0   0   1   6   0   4 322  34   4   1   3   2   3   5   1\n",
      "    4   0]\n",
      " [  5   0   0   0   0   1   0   1   3   3 373   3   0   2   2   4   2   0\n",
      "    0   0]\n",
      " [  1   9   6   3   4   2   1   0   3   2  18 301   3   1   5   3  20   4\n",
      "    9   1]\n",
      " [  1  11   6  27  12   0  10  11   6   1  11  33 237  11  10   2   0   2\n",
      "    2   0]\n",
      " [  4   5   0   1   0   0   3   7   4   0  15   0   5 304  11  17   9   4\n",
      "    5   2]\n",
      " [  4   6   1   1   0   2   1   6   2   1  18   2   5   4 317   5   3   7\n",
      "    8   1]\n",
      " [  8   3   0   1   1   2   0   1   1   1  15   1   0   2   1 343   4   0\n",
      "    3  11]\n",
      " [  5   0   0   0   0   1   1   3   5   1  12  11   1   5   8  11 262   8\n",
      "   16  14]\n",
      " [ 11   3   0   1   0   1   0   2   4   2   9   2   0   0   1  14  10 299\n",
      "   17   0]\n",
      " [ 14   2   0   0   0   3   1   4   3   0   8   6   2   7   8   8  94  12\n",
      "  136   2]\n",
      " [ 34   3   0   1   0   0   0   2   4   0   8   4   2   7   5  87  25   9\n",
      "    7  53]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "benchmark(MultinomialNB(alpha=.01), 'MultinomialNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes\n",
    "BernoulliNB might perform better on some datasets, especially those with shorter documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.114s\n",
      "test time:  0.118s\n",
      "accuracy:   0.567\n",
      "dimensionality: 101322\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.39      0.49      0.43       319\n",
      "           comp.graphics       0.54      0.64      0.59       389\n",
      " comp.os.ms-windows.misc       0.38      0.01      0.01       394\n",
      "comp.sys.ibm.pc.hardware       0.48      0.70      0.57       392\n",
      "   comp.sys.mac.hardware       0.29      0.79      0.42       385\n",
      "          comp.windows.x       0.82      0.55      0.65       395\n",
      "            misc.forsale       0.80      0.67      0.73       390\n",
      "               rec.autos       0.48      0.70      0.57       396\n",
      "         rec.motorcycles       0.37      0.78      0.50       398\n",
      "      rec.sport.baseball       0.77      0.79      0.78       397\n",
      "        rec.sport.hockey       0.97      0.70      0.82       399\n",
      "               sci.crypt       0.79      0.50      0.61       396\n",
      "         sci.electronics       0.58      0.57      0.58       393\n",
      "                 sci.med       0.86      0.57      0.68       396\n",
      "               sci.space       0.79      0.54      0.64       394\n",
      "  soc.religion.christian       0.70      0.62      0.66       398\n",
      "      talk.politics.guns       0.63      0.46      0.53       364\n",
      "   talk.politics.mideast       0.91      0.53      0.67       376\n",
      "      talk.politics.misc       0.54      0.34      0.42       310\n",
      "      talk.religion.misc       0.33      0.20      0.25       251\n",
      "\n",
      "             avg / total       0.63      0.57      0.56      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[155   1   0   1  25   0   4  16  27   7   0   2   4   1   3  34   2   5\n",
      "    8  24]\n",
      " [  1 248   0  24  58  13   3   4   9   0   0   8   8   3   7   1   0   1\n",
      "    1   0]\n",
      " [  3  61   3 139 103  29   4   9  13   0   0   9   7   4   7   1   0   0\n",
      "    0   2]\n",
      " [  0   9   2 273  74   2   7   2   3   0   0   4  16   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   7   1  27 303   0   6   9   7   0   0   2  15   0   8   0   0   0\n",
      "    0   0]\n",
      " [  0  70   1  18  56 216   2   3  18   1   0   3   5   2   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0  29  52   1 260  15  13   3   1   0   6   2   4   2   0   1\n",
      "    0   0]\n",
      " [  1   3   0   1  34   0   6 276  57   1   0   1   9   1   1   1   1   0\n",
      "    2   1]\n",
      " [  2   1   0   0  28   0   3  33 309   2   0   1  11   0   0   0   4   1\n",
      "    2   1]\n",
      " [  6   2   0   2  22   0   1   7  17 314   6   0   3   1   0   1   5   0\n",
      "   10   0]\n",
      " [  2   1   1   0  25   0   2  10  25  44 281   1   2   1   1   0   1   0\n",
      "    2   0]\n",
      " [ 15   9   0  10  51   1   3  21  42   5   0 199  19   1   6   0   6   1\n",
      "    6   1]\n",
      " [  2  15   0  27  49   1   8  19  21   3   0  14 224   7   2   0   0   0\n",
      "    1   0]\n",
      " [ 11   5   0   7  40   0   5  29  35   1   0   0  19 226   6   4   1   2\n",
      "    4   1]\n",
      " [ 10  15   0   2  29   2   5  34  41   3   0   0  24   5 212   2   1   1\n",
      "    8   0]\n",
      " [ 56   6   0   1  23   0   2   6  24   2   0   0   2   1   0 246   2   0\n",
      "    3  24]\n",
      " [ 17   0   0   1  27   0   1  32  59   3   1   3   3   2   1   2 167   3\n",
      "   21  21]\n",
      " [ 48   0   0   1  16   0   2  10  34   9   0   2   4   0   1  10   6 201\n",
      "   20  12]\n",
      " [ 24   1   0   1  15   0   2  25  37   7   0   1   2   3   6   3  59   3\n",
      "  106  15]\n",
      " [ 49   1   0   1  19   0   0  18  38   4   0   2   3   4   3  43  10   3\n",
      "    2  51]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "benchmark(BernoulliNB(alpha=.01), 'BernoulliNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 4.561s\n",
      "test time:  0.026s\n",
      "accuracy:   0.681\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.52      0.47      0.50       319\n",
      "           comp.graphics       0.66      0.70      0.68       389\n",
      " comp.os.ms-windows.misc       0.64      0.64      0.64       394\n",
      "comp.sys.ibm.pc.hardware       0.63      0.64      0.64       392\n",
      "   comp.sys.mac.hardware       0.72      0.69      0.71       385\n",
      "          comp.windows.x       0.83      0.69      0.75       395\n",
      "            misc.forsale       0.75      0.78      0.77       390\n",
      "               rec.autos       0.74      0.69      0.72       396\n",
      "         rec.motorcycles       0.78      0.73      0.75       398\n",
      "      rec.sport.baseball       0.52      0.82      0.64       397\n",
      "        rec.sport.hockey       0.87      0.86      0.87       399\n",
      "               sci.crypt       0.82      0.71      0.76       396\n",
      "         sci.electronics       0.60      0.56      0.58       393\n",
      "                 sci.med       0.76      0.76      0.76       396\n",
      "               sci.space       0.74      0.72      0.73       394\n",
      "  soc.religion.christian       0.62      0.78      0.69       398\n",
      "      talk.politics.guns       0.59      0.63      0.61       364\n",
      "   talk.politics.mideast       0.82      0.73      0.77       376\n",
      "      talk.politics.misc       0.53      0.47      0.50       310\n",
      "      talk.religion.misc       0.40      0.27      0.33       251\n",
      "\n",
      "             avg / total       0.69      0.68      0.68      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[150   2   3   2   1   0   5   3   3  11   2   1   8   9  10  54   6  11\n",
      "    9  29]\n",
      " [  3 274  22   9   8  22   6   2   1  11   1   8   8   3   8   2   0   0\n",
      "    0   1]\n",
      " [  3  21 253  34  14   9   2   2   2  16   3   4   1   8   9   3   1   1\n",
      "    7   1]\n",
      " [  0  12  35 252  26   6  12   0   0  10   2   4  28   0   2   0   0   0\n",
      "    2   1]\n",
      " [  1   8   8  24 267   4  15   3   3  16   1   4  18   3   5   2   2   0\n",
      "    0   1]\n",
      " [  2  40  33   7   5 274   1   2   3   9   0   3   4   1   4   1   1   2\n",
      "    1   2]\n",
      " [  1   5   2  13  17   1 304   7   3  10   1   1   9   2   2   3   4   2\n",
      "    1   2]\n",
      " [  3   4   3   3   4   1  10 275  19  30   3   1  16   1   6   2   3   5\n",
      "    6   1]\n",
      " [  3   2   3   2   2   0   4  23 289  25   3   1  12   4   6   4   3   2\n",
      "    8   2]\n",
      " [  1   3   0   3   0   1   7   3   5 326  23   1   2   5   4   5   1   2\n",
      "    5   0]\n",
      " [  2   1   2   1   1   0   0   2   3  25 344   0   0   3   0   3   5   0\n",
      "    3   4]\n",
      " [  5   5   7   4   3   3   5   2   3  18   2 283  10   5   5   3  16   3\n",
      "    9   5]\n",
      " [  4  10   7  31  15   7  14  14  10  15   4  13 222   8   7   2   3   2\n",
      "    3   2]\n",
      " [  8   9   3   2   1   0   3   8   3  17   2   0   5 302   7  10   3   6\n",
      "    5   2]\n",
      " [  4   9   5   2   4   0   4   7   7  20   2   1  16  10 284   2   5   1\n",
      "   10   1]\n",
      " [ 25   2   2   3   0   1   3   0   1  14   0   2   3   5   2 311   0   2\n",
      "    5  17]\n",
      " [  6   4   2   3   1   1   3   9   6  14   0  11   0   7   8   8 230  10\n",
      "   26  15]\n",
      " [ 26   1   2   2   0   1   2   2   3  13   1   3   2   2   3   8   6 275\n",
      "   18   6]\n",
      " [ 13   1   1   0   0   0   1   5   4  11   2   3   4   8   8   2  85   5\n",
      "  146  11]\n",
      " [ 26   4   1   3   3   1   2   4   1  12   0   1   3  10   4  73  18   6\n",
      "   10  69]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))]), 'LinearSVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxDgAAHQixgEAoBMxDgAAnYhxAADo5P8AtV5Mr3gc6fEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20468a8550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make some plots\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
