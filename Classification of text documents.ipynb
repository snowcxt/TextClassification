{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print classifier result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf, name):\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "    \n",
    "    joblib.dump(clf, 'models/' + name + '.pkl') \n",
    "    \n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "        print()\n",
    "    \n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,\n",
    "                                        target_names=target_names))\n",
    "\n",
    "\n",
    "#     print(\"confusion matrix:\")\n",
    "#     print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    results.append([clf_descr, score, train_time, test_time])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 13.782MB (training set)\n",
      "7532 documents - 8.262MB (test set)\n",
      "\n",
      "categories:  ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "categories = None\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "    \n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "target_names = data_train.target_names\n",
    "joblib.dump(target_names, 'categories.pkl') \n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print()\n",
    "\n",
    "print(\"categories: \", target_names)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 11314, n_features: 101322\n",
      "\n",
      "n_samples: 7532, n_features: 101322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.141s\n",
      "test time:  0.042s\n",
      "accuracy:   0.696\n",
      "dimensionality: 101322\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.56      0.43      0.49       319\n",
      "           comp.graphics       0.65      0.71      0.68       389\n",
      " comp.os.ms-windows.misc       0.75      0.46      0.57       394\n",
      "comp.sys.ibm.pc.hardware       0.59      0.72      0.65       392\n",
      "   comp.sys.mac.hardware       0.71      0.69      0.70       385\n",
      "          comp.windows.x       0.79      0.75      0.77       395\n",
      "            misc.forsale       0.81      0.72      0.76       390\n",
      "               rec.autos       0.76      0.72      0.74       396\n",
      "         rec.motorcycles       0.76      0.73      0.74       398\n",
      "      rec.sport.baseball       0.94      0.81      0.87       397\n",
      "        rec.sport.hockey       0.59      0.93      0.72       399\n",
      "               sci.crypt       0.72      0.76      0.74       396\n",
      "         sci.electronics       0.74      0.60      0.66       393\n",
      "                 sci.med       0.84      0.77      0.80       396\n",
      "               sci.space       0.75      0.80      0.78       394\n",
      "  soc.religion.christian       0.59      0.86      0.70       398\n",
      "      talk.politics.guns       0.56      0.72      0.63       364\n",
      "   talk.politics.mideast       0.81      0.80      0.80       376\n",
      "      talk.politics.misc       0.56      0.44      0.49       310\n",
      "      talk.religion.misc       0.47      0.21      0.29       251\n",
      "\n",
      "             avg / total       0.70      0.70      0.69      7532\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "benchmark(MultinomialNB(alpha=.01), 'MultinomialNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes\n",
    "BernoulliNB might perform better on some datasets, especially those with shorter documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.208s\n",
      "test time:  0.126s\n",
      "accuracy:   0.567\n",
      "dimensionality: 101322\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.39      0.49      0.43       319\n",
      "           comp.graphics       0.54      0.64      0.59       389\n",
      " comp.os.ms-windows.misc       0.38      0.01      0.01       394\n",
      "comp.sys.ibm.pc.hardware       0.48      0.70      0.57       392\n",
      "   comp.sys.mac.hardware       0.29      0.79      0.42       385\n",
      "          comp.windows.x       0.82      0.55      0.65       395\n",
      "            misc.forsale       0.80      0.67      0.73       390\n",
      "               rec.autos       0.48      0.70      0.57       396\n",
      "         rec.motorcycles       0.37      0.78      0.50       398\n",
      "      rec.sport.baseball       0.77      0.79      0.78       397\n",
      "        rec.sport.hockey       0.97      0.70      0.82       399\n",
      "               sci.crypt       0.79      0.50      0.61       396\n",
      "         sci.electronics       0.58      0.57      0.58       393\n",
      "                 sci.med       0.86      0.57      0.68       396\n",
      "               sci.space       0.79      0.54      0.64       394\n",
      "  soc.religion.christian       0.70      0.62      0.66       398\n",
      "      talk.politics.guns       0.63      0.46      0.53       364\n",
      "   talk.politics.mideast       0.91      0.53      0.67       376\n",
      "      talk.politics.misc       0.54      0.34      0.42       310\n",
      "      talk.religion.misc       0.33      0.20      0.25       251\n",
      "\n",
      "             avg / total       0.63      0.57      0.56      7532\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "benchmark(BernoulliNB(alpha=.01), 'BernoulliNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 11.428s\n",
      "test time:  0.051s\n",
      "accuracy:   0.681\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.52      0.47      0.50       319\n",
      "           comp.graphics       0.65      0.70      0.68       389\n",
      " comp.os.ms-windows.misc       0.64      0.64      0.64       394\n",
      "comp.sys.ibm.pc.hardware       0.63      0.65      0.64       392\n",
      "   comp.sys.mac.hardware       0.72      0.69      0.70       385\n",
      "          comp.windows.x       0.82      0.69      0.75       395\n",
      "            misc.forsale       0.76      0.78      0.77       390\n",
      "               rec.autos       0.73      0.69      0.71       396\n",
      "         rec.motorcycles       0.79      0.73      0.76       398\n",
      "      rec.sport.baseball       0.52      0.82      0.64       397\n",
      "        rec.sport.hockey       0.87      0.86      0.86       399\n",
      "               sci.crypt       0.82      0.71      0.76       396\n",
      "         sci.electronics       0.60      0.56      0.58       393\n",
      "                 sci.med       0.77      0.76      0.77       396\n",
      "               sci.space       0.74      0.72      0.73       394\n",
      "  soc.religion.christian       0.63      0.78      0.69       398\n",
      "      talk.politics.guns       0.59      0.63      0.61       364\n",
      "   talk.politics.mideast       0.82      0.73      0.77       376\n",
      "      talk.politics.misc       0.53      0.47      0.50       310\n",
      "      talk.religion.misc       0.40      0.28      0.33       251\n",
      "\n",
      "             avg / total       0.69      0.68      0.68      7532\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))]), 'LinearSVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxDgAAHQixgEAoBMxDgAAnYhxAADo5P8AUE5Mrxg6Xx8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x211d0350b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make some plots\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
