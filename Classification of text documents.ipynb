{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print classifier result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf, name):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "    \n",
    "    joblib.dump(clf, name + '.pkl') \n",
    "    \n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "        print()\n",
    "    \n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,\n",
    "                                        target_names=target_names))\n",
    "\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    results.append([clf_descr, score, train_time, test_time])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 13.782MB (training set)\n",
      "7532 documents - 8.262MB (test set)\n",
      "\n",
      "categories:  ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "categories = None\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "    \n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "target_names = data_train.target_names\n",
    "joblib.dump(target_names, 'categories.pkl') \n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print()\n",
    "\n",
    "print(\"categories: \", target_names)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 11314, n_features: 101322\n",
      "\n",
      "n_samples: 7532, n_features: 101322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.112s\n",
      "test time:  0.023s\n",
      "accuracy:   0.696\n",
      "dimensionality: 101322\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.56      0.43      0.49       319\n",
      "           comp.graphics       0.65      0.71      0.68       389\n",
      " comp.os.ms-windows.misc       0.75      0.46      0.57       394\n",
      "comp.sys.ibm.pc.hardware       0.59      0.72      0.65       392\n",
      "   comp.sys.mac.hardware       0.71      0.69      0.70       385\n",
      "          comp.windows.x       0.79      0.75      0.77       395\n",
      "            misc.forsale       0.81      0.72      0.76       390\n",
      "               rec.autos       0.76      0.72      0.74       396\n",
      "         rec.motorcycles       0.76      0.73      0.74       398\n",
      "      rec.sport.baseball       0.94      0.81      0.87       397\n",
      "        rec.sport.hockey       0.59      0.93      0.72       399\n",
      "               sci.crypt       0.72      0.76      0.74       396\n",
      "         sci.electronics       0.74      0.60      0.66       393\n",
      "                 sci.med       0.84      0.77      0.80       396\n",
      "               sci.space       0.75      0.80      0.78       394\n",
      "  soc.religion.christian       0.59      0.86      0.70       398\n",
      "      talk.politics.guns       0.56      0.72      0.63       364\n",
      "   talk.politics.mideast       0.81      0.80      0.80       376\n",
      "      talk.politics.misc       0.56      0.44      0.49       310\n",
      "      talk.religion.misc       0.47      0.21      0.29       251\n",
      "\n",
      "             avg / total       0.70      0.70      0.69      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[138   1   2   2   2   2   0   3   3   2  12   3   0   3  10  74  13  12\n",
      "   12  25]\n",
      " [  2 278   6  17  15  24   6   0   5   3   6  13   2   0   9   2   0   1\n",
      "    0   0]\n",
      " [  4  30 181  73  16  30   4   2   5   0  16  12   3   2   8   1   0   1\n",
      "    3   3]\n",
      " [  0  13  20 284  29   4  10   2   0   0   8   5  16   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0  11   8  32 265   5   8   7   2   0  14   7  13   2   6   2   1   1\n",
      "    1   0]\n",
      " [  0  46   9   9   7 297   1   0   0   1   7   5   5   3   4   0   1   0\n",
      "    0   0]\n",
      " [  1   4   1  32  18   0 281  14   7   3  11   1   7   2   4   1   1   0\n",
      "    2   0]\n",
      " [  1   1   1   1   1   0   9 285  31   1  25   4  10   1   6   3   4   3\n",
      "    9   0]\n",
      " [  8   3   1   0   2   3   7  26 290   1  15   0   8   3   6   3  11   3\n",
      "    7   1]\n",
      " [  5   2   0   0   0   1   6   0   4 322  34   4   1   3   2   3   5   1\n",
      "    4   0]\n",
      " [  5   0   0   0   0   1   0   1   3   3 373   3   0   2   2   4   2   0\n",
      "    0   0]\n",
      " [  1   9   6   3   4   2   1   0   3   2  18 301   3   1   5   3  20   4\n",
      "    9   1]\n",
      " [  1  11   6  27  12   0  10  11   6   1  11  33 237  11  10   2   0   2\n",
      "    2   0]\n",
      " [  4   5   0   1   0   0   3   7   4   0  15   0   5 304  11  17   9   4\n",
      "    5   2]\n",
      " [  4   6   1   1   0   2   1   6   2   1  18   2   5   4 317   5   3   7\n",
      "    8   1]\n",
      " [  8   3   0   1   1   2   0   1   1   1  15   1   0   2   1 343   4   0\n",
      "    3  11]\n",
      " [  5   0   0   0   0   1   1   3   5   1  12  11   1   5   8  11 262   8\n",
      "   16  14]\n",
      " [ 11   3   0   1   0   1   0   2   4   2   9   2   0   0   1  14  10 299\n",
      "   17   0]\n",
      " [ 14   2   0   0   0   3   1   4   3   0   8   6   2   7   8   8  94  12\n",
      "  136   2]\n",
      " [ 34   3   0   1   0   0   0   2   4   0   8   4   2   7   5  87  25   9\n",
      "    7  53]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "benchmark(MultinomialNB(alpha=.01), 'MultinomialNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes\n",
    "BernoulliNB might perform better on some datasets, especially those with shorter documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.109s\n",
      "test time:  0.103s\n",
      "accuracy:   0.567\n",
      "dimensionality: 101322\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.39      0.49      0.43       319\n",
      "           comp.graphics       0.54      0.64      0.59       389\n",
      " comp.os.ms-windows.misc       0.38      0.01      0.01       394\n",
      "comp.sys.ibm.pc.hardware       0.48      0.70      0.57       392\n",
      "   comp.sys.mac.hardware       0.29      0.79      0.42       385\n",
      "          comp.windows.x       0.82      0.55      0.65       395\n",
      "            misc.forsale       0.80      0.67      0.73       390\n",
      "               rec.autos       0.48      0.70      0.57       396\n",
      "         rec.motorcycles       0.37      0.78      0.50       398\n",
      "      rec.sport.baseball       0.77      0.79      0.78       397\n",
      "        rec.sport.hockey       0.97      0.70      0.82       399\n",
      "               sci.crypt       0.79      0.50      0.61       396\n",
      "         sci.electronics       0.58      0.57      0.58       393\n",
      "                 sci.med       0.86      0.57      0.68       396\n",
      "               sci.space       0.79      0.54      0.64       394\n",
      "  soc.religion.christian       0.70      0.62      0.66       398\n",
      "      talk.politics.guns       0.63      0.46      0.53       364\n",
      "   talk.politics.mideast       0.91      0.53      0.67       376\n",
      "      talk.politics.misc       0.54      0.34      0.42       310\n",
      "      talk.religion.misc       0.33      0.20      0.25       251\n",
      "\n",
      "             avg / total       0.63      0.57      0.56      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[155   1   0   1  25   0   4  16  27   7   0   2   4   1   3  34   2   5\n",
      "    8  24]\n",
      " [  1 248   0  24  58  13   3   4   9   0   0   8   8   3   7   1   0   1\n",
      "    1   0]\n",
      " [  3  61   3 139 103  29   4   9  13   0   0   9   7   4   7   1   0   0\n",
      "    0   2]\n",
      " [  0   9   2 273  74   2   7   2   3   0   0   4  16   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   7   1  27 303   0   6   9   7   0   0   2  15   0   8   0   0   0\n",
      "    0   0]\n",
      " [  0  70   1  18  56 216   2   3  18   1   0   3   5   2   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0  29  52   1 260  15  13   3   1   0   6   2   4   2   0   1\n",
      "    0   0]\n",
      " [  1   3   0   1  34   0   6 276  57   1   0   1   9   1   1   1   1   0\n",
      "    2   1]\n",
      " [  2   1   0   0  28   0   3  33 309   2   0   1  11   0   0   0   4   1\n",
      "    2   1]\n",
      " [  6   2   0   2  22   0   1   7  17 314   6   0   3   1   0   1   5   0\n",
      "   10   0]\n",
      " [  2   1   1   0  25   0   2  10  25  44 281   1   2   1   1   0   1   0\n",
      "    2   0]\n",
      " [ 15   9   0  10  51   1   3  21  42   5   0 199  19   1   6   0   6   1\n",
      "    6   1]\n",
      " [  2  15   0  27  49   1   8  19  21   3   0  14 224   7   2   0   0   0\n",
      "    1   0]\n",
      " [ 11   5   0   7  40   0   5  29  35   1   0   0  19 226   6   4   1   2\n",
      "    4   1]\n",
      " [ 10  15   0   2  29   2   5  34  41   3   0   0  24   5 212   2   1   1\n",
      "    8   0]\n",
      " [ 56   6   0   1  23   0   2   6  24   2   0   0   2   1   0 246   2   0\n",
      "    3  24]\n",
      " [ 17   0   0   1  27   0   1  32  59   3   1   3   3   2   1   2 167   3\n",
      "   21  21]\n",
      " [ 48   0   0   1  16   0   2  10  34   9   0   2   4   0   1  10   6 201\n",
      "   20  12]\n",
      " [ 24   1   0   1  15   0   2  25  37   7   0   1   2   3   6   3  59   3\n",
      "  106  15]\n",
      " [ 49   1   0   1  19   0   0  18  38   4   0   2   3   4   3  43  10   3\n",
      "    2  51]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "benchmark(BernoulliNB(alpha=.01), 'BernoulliNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 4.598s\n",
      "test time:  0.026s\n",
      "accuracy:   0.681\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.53      0.47      0.50       319\n",
      "           comp.graphics       0.66      0.70      0.68       389\n",
      " comp.os.ms-windows.misc       0.64      0.64      0.64       394\n",
      "comp.sys.ibm.pc.hardware       0.63      0.64      0.64       392\n",
      "   comp.sys.mac.hardware       0.72      0.69      0.70       385\n",
      "          comp.windows.x       0.82      0.69      0.75       395\n",
      "            misc.forsale       0.76      0.78      0.77       390\n",
      "               rec.autos       0.73      0.69      0.71       396\n",
      "         rec.motorcycles       0.78      0.73      0.75       398\n",
      "      rec.sport.baseball       0.52      0.82      0.64       397\n",
      "        rec.sport.hockey       0.87      0.86      0.87       399\n",
      "               sci.crypt       0.82      0.71      0.76       396\n",
      "         sci.electronics       0.60      0.56      0.58       393\n",
      "                 sci.med       0.76      0.76      0.76       396\n",
      "               sci.space       0.74      0.72      0.73       394\n",
      "  soc.religion.christian       0.63      0.78      0.69       398\n",
      "      talk.politics.guns       0.59      0.63      0.61       364\n",
      "   talk.politics.mideast       0.82      0.73      0.77       376\n",
      "      talk.politics.misc       0.53      0.47      0.50       310\n",
      "      talk.religion.misc       0.40      0.28      0.33       251\n",
      "\n",
      "             avg / total       0.69      0.68      0.68      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[150   2   3   2   1   0   5   3   3  11   2   1   8   9  10  54   6  11\n",
      "    9  29]\n",
      " [  3 274  22   9   8  22   6   2   2  11   1   8   7   3   8   2   0   0\n",
      "    0   1]\n",
      " [  3  21 252  34  14  10   2   2   2  16   3   4   1   8   9   3   1   1\n",
      "    7   1]\n",
      " [  0  12  35 252  26   6  11   0   0  10   2   4  28   0   2   0   0   0\n",
      "    2   2]\n",
      " [  1   9   8  24 266   4  15   3   3  16   1   4  18   3   5   2   2   0\n",
      "    0   1]\n",
      " [  2  40  33   7   5 274   1   2   3   9   0   3   4   1   4   1   1   2\n",
      "    1   2]\n",
      " [  1   5   2  13  17   1 304   7   3  10   1   1   9   2   2   3   4   2\n",
      "    1   2]\n",
      " [  3   4   3   3   4   1  10 275  19  30   3   1  16   1   6   2   3   5\n",
      "    6   1]\n",
      " [  3   2   3   2   2   0   4  24 289  25   3   1  12   4   6   4   3   1\n",
      "    8   2]\n",
      " [  1   3   0   3   0   1   7   3   5 326  23   1   2   5   4   5   1   2\n",
      "    5   0]\n",
      " [  2   1   2   1   1   0   0   2   3  26 343   0   0   2   0   3   5   0\n",
      "    4   4]\n",
      " [  5   5   7   4   4   3   5   2   3  18   1 283  10   5   5   3  16   3\n",
      "    9   5]\n",
      " [  4  10   7  31  15   7  14  14  10  15   4  13 222   8   7   2   3   2\n",
      "    3   2]\n",
      " [  8   9   3   2   1   0   3   9   3  17   2   0   5 301   7  10   3   6\n",
      "    5   2]\n",
      " [  4   9   5   2   4   0   4   7   7  20   2   1  16  10 284   2   5   1\n",
      "   10   1]\n",
      " [ 24   2   2   3   0   1   3   0   1  14   0   2   3   5   2 311   0   2\n",
      "    5  18]\n",
      " [  6   4   2   3   1   1   3   9   5  14   0  11   0   7   8   8 231  10\n",
      "   26  15]\n",
      " [ 26   1   2   2   0   1   2   2   3  13   1   3   2   2   3   8   6 275\n",
      "   18   6]\n",
      " [ 13   1   1   0   0   0   1   5   4  11   2   3   4   8   8   2  85   5\n",
      "  146  11]\n",
      " [ 26   4   1   3   2   1   2   4   1  12   0   1   3  10   4  72  18   6\n",
      "   11  70]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))]), 'LinearSVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu0nnV95/3PNyRCAlEE1IFiSZZyKknIkRGwGBSDyCP2\npK2HVm0VKj6eCozQmRq1S8s8qFW06KiTxajEolKVUabNxCEL0CAkgIAGCVSKyLPKYQwGBGvgN3/s\nm0yAHPbOYf+yzeu1Fsv7cN3X9b1zmeSd3772vau1FgAAYPSN6z0AAADsqsQ4AAB0IsYBAKATMQ4A\nAJ2IcQAA6ESMAwBAJ2IcAAA6EeMAjFlV9cKq+m5VPVBV/7uqvlNV83rPBTBc43sPAABbo6qenuSb\nSd6a5MtJnpbkt5P8cjseY7fW2qPba38AT2ZlHICx6pAkaa19qbX2aGvt4dbaktbajUlSVW+pqlVV\ntbaqflhVswePH15Vy6pqTVX9oKpOeXyHVXVhVX2qqi6rqoeSHF9Vu1fVh6vqzqr616r6dFVN7PKO\ngV87YhyAserWJI9W1X+rqpOq6pmPP1FVr0ryviR/kuTpSU5Jcn9VTUjy35MsSfLsJG9PclFVHbrB\nfl+b5INJJie5Ksl/zlD4z0zy/CS/keS9O/atAbuKaq31ngEAtkpVHZ7kPUlOSPLvklyW5C1JPp/k\nstbax5+0/W8n+UqSA1prjw0e+1KSH7XW3ldVFyYZ11r7k8FzleTBJDNaa7cPHjs6yeLW2tRReIvA\nrznXjAMwZrXWViV5Y5JU1WFJvpjkY0mem+T2jbzkgCQ/eTzEB/4lQ6vdj/vJBreflWRSkpVDXZ4k\nqSS7bYfxAVymAsCvh9baLUkuTDItQ0H9vI1sdneS51bVhn///WaSn264qw1u35fk4SRHtNb2Hvz3\njNbaXtt1eGCXJcYBGJOq6rCqOqOqDhzcf26S1yS5OsnnkpxZVXNqyPOr6qAk30vyUJL/UFUTqmp+\nklck+fuNHWOwgv7ZJH9bVc8eHOc3qurEHf3+gF2DGAdgrFqb5N8n+d7gk0+uTnJzkjNaa1/J0Ddh\nLh5s9/Uk+7TW/i1D38x5UoZWvS9I8ieDVfVNeU+S25JcXVU/T7I0yaGb2R5g2HwDJwAAdGJlHAAA\nOhHjAADQiRgHAIBOxDgAAHTih/6wU9tvv/3alClTeo8BADAiK1euvK+19qwtbSfG2alNmTIlK1as\n6D0GAMCIVNW/DGc7l6kAAEAnYhwAADoR4wAA0IlrxgEAxphf/epXueuuu/LII4/0HmWXt8cee+TA\nAw/MhAkTtur1YhwAYIy56667Mnny5EyZMiVV1XucXVZrLffff3/uuuuuTJ06dav24TIVAIAx5pFH\nHsm+++4rxDurquy7777b9BUKMQ4AMAYJ8Z3Dtp4HMQ4AAJ24ZhwAYIyrev923V9rC7fr/tg0K+MA\nAHSzbt263iN0JcYBABiRhx56KCeffHKOPPLITJs2LRdffHGuvfbaHHPMMTnyyCNz1FFHZe3atXnk\nkUfypje9KdOnT8+sWbNy+eWXJ0kuvPDCvOpVr8orXvGKLFiwIEly3nnnZd68eZkxY0YWLtx1VuZd\npgIAwIj84z/+Yw444IB861vfSpI88MADmTVrVi6++OLMmzcvP//5zzNx4sR8/OMfT5LcdNNNueWW\nW7JgwYLceuutSZLly5fnxhtvzD777JMlS5Zk9erVueaaa9JayymnnJIrrrgixx13XLf3OFqsjAMA\nMCLTp0/P0qVL8573vCdXXnll7rzzzuy///6ZN29ekuTpT396xo8fn6uuuip//Md/nCQ57LDDctBB\nB62P8Ze+9KXZZ599kiRLlizJkiVLMmvWrMyePTu33HJLVq9e3efNjTIr4wAAjMghhxySlStX5rLL\nLss555yTBQsWbPQj/lprm9zHnnvu+YTtzjnnnJx22mk7ZN6dmZVxAABG5O67786kSZPy+te/Pmee\neWauvvrq3H333bn22muTJGvXrs26dety3HHH5aKLLkqS3Hrrrbnzzjtz6KGHPmV/J554YhYtWpQH\nH3wwSfLTn/4099xzz+i9oY6sjAMAjHGj/VGEN910U84666yMGzcuEyZMyKc+9am01vL2t789Dz/8\ncCZOnJilS5fm9NNPz5//+Z9n+vTpGT9+fC688MLsvvvuT9nfggULsmrVqhx99NFJkr322itf/OIX\n8+xnP3tU31cPtbkvH0Bvc+fObStWrOg9BgDsVFatWpXDDz+89xgMbOx8VNXK1trcLb3WZSoAANCJ\nGAcAgE7EOAAAdCLGAQCgEzEOAACd+GhDdm7/ujL5yFN/iADkDJ8EBcDYJ8YBAMa4WrZsu+6vzZ+/\n2efXrFmTxYsX5/TTTx/xvl/+8pdn8eLF2XvvvTe5zXvf+94cd9xxOeGEE0a8/yf70Ic+lL/8y79c\nf/+YY47Jd7/73W3e7/biMhUAAEZkzZo1ueCCCzb63KOPPrrZ11522WWbDfEk+cAHPrBdQjwZivEN\n7UwhnohxAABG6Oyzz87tt9+emTNn5qyzzsqyZcty/PHH57WvfW2mT5+eJPmd3/mdzJkzJ0cccUQ+\n85nPrH/tlClTct999+WOO+7I4Ycfnre85S054ogjsmDBgjz88MNJkje+8Y356le/un77hQsXZvbs\n2Zk+fXpuueWWJMm9996bl770pZk9e3ZOO+20HHTQQbnvvvueMufDDz+cmTNn5nWve12SoZ/umSTL\nli3Li170orz61a/OIYcckrPPPjsXXXRRjjrqqEyfPj233377+uP8/u//fubNm5d58+blO9/5znb9\ntRTjAACMyLnnnpvnPe95ueGGG3LeeeclSa655pp88IMfzA9/+MMkyaJFi7Jy5cqsWLEi559/fu6/\n//6n7Gf16tV529velh/84AfZe++9c8kll2z0ePvtt1+uu+66vPWtb82HP/zhJMn73//+vPjFL851\n112X3/3d382dd9650TknTpyYG264IRdddNFTnv/+97+fj3/847npppvyhS98IbfeemuuueaavPnN\nb84nPvGJJMk73/nOvPvd7861116bSy65JG9+85u37hdtE1wzDgDANjvqqKMyderU9ffPP//8fO1r\nX0uS/OQnP8nq1auz7777PuE1U6dOzcyZM5Mkc+bMyR133LHRff/e7/3e+m3+4R/+IUly1VVXrd//\ny172sjzzmc8c8czz5s3L/vvvnyR53vOelwULFiRJpk+fnssvvzxJsnTp0vX/wEiSn//851m7dm0m\nT5484uNtjBgHAGCb7bnnnutvL1u2LEuXLs3y5cszadKkzJ8/P4888shTXrP77ruvv73bbrutv0xl\nU9vttttuWbduXZKktW3/VK0Njz9u3Lj198eNG7f+OI899liWL1+eiRMnbvPxNsZlKgAAjMjkyZOz\ndu3aTT7/wAMP5JnPfGYmTZqUW265JVdfffV2n+GFL3xhvvzlLydJlixZkp/97Gcb3W7ChAn51a9+\ntdXHWbBgQT75yU+uv3/DDTds9b42xso4AMAYt6WPItze9t133xx77LGZNm1aTjrppJx88slPeP5l\nL3tZPv3pT2fGjBk59NBD84IXvGC7z7Bw4cK85jWvycUXX5wXvehF2X///Td66cipp56aGTNmZPbs\n2Ru9bnxLzj///LztbW/LjBkzsm7duhx33HH59Kc/vT3eQpKktscSP+woc59bbcW7ek/BTskP/QF2\nYatWrcrhhx/ee4yufvnLX2a33XbL+PHjs3z58rz1rW/d7qvWw7Wx81FVK1trc7f0WivjAACMOXfe\neWde/epX57HHHsvTnva0fPazn+090lYR4wAAjDkHH3xwrr/++t5jbDPfwAkAAJ2IcQAA6ESMAwBA\nJ2IcAAA68Q2cAABj3Udq++5vCx8fu2bNmixevDinn376Vu3+Yx/7WE499dRMmjRpi8+9/OUvz+LF\ni7P33ntv1bF2dlbGAQAYkTVr1uSCCy7Y6td/7GMfyy9+8YthPXfZZZf92oZ4IsYBABihs88+O7ff\nfntmzpyZs846K0ly3nnnZd68eZkxY0YWLlyYJHnooYdy8skn58gjj8y0adNy8cUX5/zzz8/dd9+d\n448/Pscff/wT9rux56ZMmZL77rsvd9xxRw477LC8+c1vzrRp0/K6170uS5cuzbHHHpuDDz4411xz\nzfpj/umf/mnmzZuXWbNm5Rvf+MYo/sqMnMtUAAAYkXPPPTc333zz+p94uWTJkqxevTrXXHNNWms5\n5ZRTcsUVV+Tee+/NAQcckG9961tJkgceeCDPeMYz8tGPfjSXX3559ttvvyfs9x3veMcmn0uS2267\nLV/5ylfymc98JvPmzcvixYtz1VVX5dJLL82HPvShfP3rX88HP/jBvPjFL86iRYuyZs2aHHXUUTnh\nhBOy55577vhfmK1gZRwAgG2yZMmSLFmyJLNmzcrs2bNzyy23ZPXq1Zk+fXqWLl2a97znPbnyyivz\njGc8Y5uOM3Xq1EyfPj3jxo3LEUcckZe85CWpqkyfPj133HHH+lnOPffczJw5M/Pnz88jjzySO++8\nczu8yx3DyjgAANuktZZzzjknp5122lOeW7lyZS677LKcc845WbBgQd773vdu9XF233339bfHjRu3\n/v64ceOybt269bNccsklOfTQQ7f6OKPJyjgAACMyefLkrF27dv39E088MYsWLcqDDz6YJPnpT3+a\ne+65J3fffXcmTZqU17/+9TnzzDNz3XXXbfT1m9v3SJ144on5xCc+kdaGPhHm+uuv3+p9jQYr4wAA\nY90WPopwe9t3331z7LHHZtq0aTnppJNy3nnnZdWqVTn66KOTJHvttVe++MUv5rbbbstZZ52VcePG\nZcKECfnUpz6VJDn11FNz0kknZf/998/ll1/+hH1v7rnh+Ku/+qu8613vyowZM9Jay5QpU/LNb35z\n29/0DlKP/6sBdkZzn1ttxbt6T8FOaZT/4gHYmaxatSqHH3547zEY2Nj5qKqVrbW5W3qty1QAAKAT\nMQ4AAJ2IcQCAMcilxjuHbT0PYhwAYIzZY489cv/99wvyzlpruf/++7PHHnts9T58mgoAwBhz4IEH\n5q677sq9997be5Rd3h577JEDDzxwq18vxgEAxpgJEyZk6tSpvcdgO3CZCgAAdCLGAQCgEzEOAACd\nuGacndtz5iRnrOg9BQDADmFlHAAAOhHjAADQiRgHAIBOxDgAAHQixgEAoBMxDgAAnYhxAADoRIwD\nAEAnYhwAADoR4wAA0IkYBwCATsQ4AAB0IsYBAKATMQ4AAJ2IcQAA6GR87wFgc1auXZtatqz3GADA\nr4k2f37vEZ7AyjgAAHQixgEAoBMxDgAAnYhxAADoRIwDAEAnYhwAADoR4wAA0IkYBwCATsQ4AAB0\nIsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ2IcAAA6EeMAANCJGAcAgE7EOAAAdCLGAQCgEzEOAACdiHEA\nAOhEjAMAQCdiHAAAOhHjAADQiRgHAIBOxDgAAHQixgEAoBMxDgAAnYhxAADoRIwDAEAnYhwAADoR\n4wAA0IkYBwCATsQ4AAB0Mr73ALA5cyZPzor583uPAQCwQ1gZBwCATsQ4AAB0IsYBAKATMQ4AAJ2I\ncQAA6ESMAwBAJ2IcAAA6EeMAANCJGAcAgE7EOAAAdCLGAQCgEzEOAACdiHEAAOhEjAMAQCdiHAAA\nOhHjAADQSbXWes8Am1R1QEtO6z0GAFvQ2sLeI8BOpapWttbmbmk7K+MAANCJGAcAgE7EOAAAdCLG\nAQCgEzEOAACdiHEAAOhEjAMAQCdiHAAAOhHjAADQyRZjvKoeraobqurmqvpKVU0aPP7drT1oVS2r\nqrmD25dV1d5buy8AABirhrMy/nBrbWZrbVqSf0vy50nSWjtmewzQWnt5a23N9tgXAACMJSO9TOXK\nJM9Pkqp6cPC/86vqiqr6WlX9sKo+XVXjBs8tqKrlVXXdYFV9ryfvsKruqKr9qmpKVa2qqs9W1Q+q\naklVTRxs87yq+seqWllVV1bVYdv2tgEAoL9hx3hVjU9yUpKbNvL0UUnOSDI9yfOS/F5V7ZfkPyU5\nobU2O8mKJH+xhcMcnOTvWmtHJFmT5PcHj38mydtba3OSnJnkguHODQAAO6vxw9hmYlXdMLh9ZZL/\nupFtrmmt/XOSVNWXkrwwySNJfivJd6oqSZ6WZPkWjvXj1trjx1qZZMpgNf2YJF8Z7CdJdh/G3AAA\nsFMbTow/3FqbuYVt2kbuV5L/2Vp7zQjm+eUGtx9NMjFDq/drhjEDAACMKdvrow2Pqqqpg2vF/zDJ\nVUmuTnJsVT1+jfmkqjpkpDturf08yY+r6lWD/VRVHbmd5gYAgG62V4wvT3JukpuT/DjJ11pr9yZ5\nY5IvVdWNGYrzrf3Gy9cl+bOq+n6SHyR55TZPDAAAnVVrT77CZIQ7qJqf5MzW2v+zXSaCDVQd0JLT\neo8BwBa0trD3CLBTqaqVrbW5W9rOT+AEAIBOhvMNnJvVWluWZNk2TwIAALsYK+MAANCJGAcAgE7E\nOAAAdCLGAQCgEzEOAACdiHEAAOhEjAMAQCdiHAAAOhHjAADQiRgHAIBOxDgAAHQixgEAoBMxDgAA\nnYzvPQBszpw5B2TFioW9xwAA2CGsjAMAQCdiHAAAOhHjAADQiRgHAIBOxDgAAHQixgEAoBMxDgAA\nnYhxAADoRIwDAEAnYhwAADoR4wAA0IkYBwCATsQ4AAB0IsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ2Ic\nAAA6EeMAANCJGAcAgE7EOAAAdCLGAQCgEzEOAACdiHEAAOhEjAMAQCdiHAAAOhHjAADQiRgHAIBO\nxDgAAHQixgEAoBMxDgAAnYhxAADoZHzvAWCz/nVl8pHqPQUA8OvijNZ7giewMg4AAJ2IcQAA6ESM\nAwBAJ2IcAAA6EeMAANCJGAcAgE7EOAAAdCLGAQCgEzEOAACdiHEAAOhEjAMAQCdiHAAAOhHjAADQ\niRgHAIBOxDgAAHQixgEAoBMxDgAAnYhxAADoRIwDAEAnYhwAADoR4wAA0IkYBwCATsQ4AAB0IsYB\nAKATMQ4AAJ2IcQAA6ESMAwBAJ2IcAAA6EeMAANCJGAcAgE7EOAAAdCLGAQCgEzEOAACdjO89AGzW\nc+YkZ6zoPQUAwA5hZRwAADoR4wAA0IkYBwCATsQ4AAB0IsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ2Ic\nAAA6EeMAANCJGAcAgE7EOAAAdCLGAQCgEzEOAACdiHEAAOhEjAMAQCfjew8Am7Ny7drUsmXD3r7N\nn7/DZgEA2N6sjAMAQCdiHAAAOhHjAADQiRgHAIBOxDgAAHQixgEAoBMxDgAAnYhxAADoRIwDAEAn\nYhwAADoR4wAA0IkYBwCATsQ4AAB0IsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ2IcAAA6EeMAANCJGAcA\ngE7EOAAAdCLGAQCgEzEOAACdiHEAAOhEjAMAQCdiHAAAOhHjAADQiRgHAIBOxDgAAHQixgEAoBMx\nDgAAnYhxAADoZHzvAWBz5kyenBXz5/ceAwBgh7AyDgAAnYhxAADoRIwDAEAnYhwAADoR4wAA0IkY\nBwCATsQ4AAB0IsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ2IcAAA6EeMAANCJGAcAgE7EOAAAdCLGAQCg\nk2qt9Z4BNqnqgJac1nsMgBFpbWHvEYDOqmpla23ulrazMg4AAJ2IcQAA6ESMAwBAJ2IcAAA6EeMA\nANCJGAcAgE7EOAAAdCLGAQCgEzEOAACdbDHGq+rRqrqhqr5fVddV1TGjMdgmZplSVTcPbs+vqm8O\nbp9SVWcPbr+vqn5RVc/e4HUPbnB7p3k/AADs2oazMv5wa21ma+3IJOck+Zvh7ryG7PDV99bapa21\nczd46L4kZ2xi861+PwAAsD2NNJSfnuRnj9+pqrOq6tqqurGq3j94bEpVraqqC5Jcl+S5VfVgVX1w\nsBp9dVU9Z7DtQVX17cHrv11Vvzl4/MKq+oMNjvNgNqOq3lhVn9zgoUVJ/rCq9hnJ+wEAgNE0nBif\nOLis45Ykn0vy10lSVQuSHJzkqCQzk8ypquMGrzk0yedba7Naa/+SZM8kVw9Wo69I8pbBdp8cbDcj\nyUVJzt9O7+vBDAX5O4f7fgAAYLSN5DKVw5K8LMnnq6qSLBj8d32GVsAPy1CcJ8m/tNau3mAf/5bk\nm4PbK5NMGdw+Osniwe0vJHnhVr6PjTk/yRuq6ulPenxT7wcAAEbV+JFs3FpbXlX7JXlWkkryN621\n/7LhNlU1JclDT3rpr1prbXD70c0c9/Ft1mXwD4VBKD9tJHMOZl1TVYuTnL6ZbTZ8P/eM9BgAALAt\nRnTNeFUdlmS3JPcn+ackf1pVew2e+40NP8FkmL6b5I8Gt1+X5KrB7TuSzBncfmWSCSPc7+M+muS0\nbCL+n/R+AABgVA1nZXxiVd0wuF1J3tBaezTJkqo6PMnywVUeDyZ5fYZWvofrHUkWVdVZSe5N8qbB\n459N8o2quibJt/PUlfZhaa3dV1VfS/LuYbwfAAAYVfV/rx6BnU/VAW3oixsAY0drC3uPAHRWVStb\na3O3tJ2fwAkAAJ2IcQAA6ESMAwBAJ2IcAAA6EeMAANCJGAcAgE7EOAAAdCLGAQCgEzEOAACdiHEA\nAOhEjAMAQCdiHAAAOhHjAADQiRgHAIBOxDgAAHQyvvcAsDlz5hyQFSsW9h4DAGCHsDIOAACdiHEA\nAOhEjAMAQCdiHAAAOhHjAADQiRgHAIBOxDgAAHQixgEAoBMxDgAAnYhxAADoRIwDAEAnYhwAADoR\n4wAA0IkYBwCATsQ4AAB0IsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ2IcAAA6EeMAANCJGAcAgE7EOAAA\ndCLGAQCgEzEOAACdiHEAAOhEjAMAQCdiHAAAOhHjAADQiRgHAIBOxDgAAHQixgEAoBMxDgAAnYzv\nPQBs1r+uTD5SvadgRzij9Z4AALqzMg4AAJ2IcQAA6ESMAwBAJ2IcAAA6EeMAANCJGAcAgE7EOAAA\ndCLGAQCgEzEOAACdiHEAAOhEjAMAQCdiHAAAOhHjAADQiRgHAIBOxDgAAHQixgEAoBMxDgAAnYhx\nAADoRIwDAEAnYhwAADoR4wAA0IkYBwCATsQ4AAB0IsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ2IcAAA6\nEeMAANCJGAcAgE7EOAAAdCLGAQCgk/G9B4DNes6c5IwVvacAANghrIwDAEAnYhwAADoR4wAA0IkY\nBwCATsQ4AAB0IsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ2IcAAA6EeMAANCJGAcAgE7EOAAAdCLGAQCg\nEzEOAACdiHEAAOhkfO8BYHNWrl2bWrZsRK9p8+fvkFkAALY3K+MAANCJGAcAgE7EOAAAdCLGAQCg\nEzEOAACdiHEAAOhEjAMAQCdiHAAAOhHjAADQiRgHAIBOxDgAAHQixgEAoBMxDgAAnYhxAADoRIwD\nAEAnYhwAADoR4wAA0IkYBwCATsQ4AAB0IsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ2IcAAA6EeMAANCJ\nGAcAgE7EOAAAdCLGAQCgEzEOAACdiHEAAOhEjAMAQCdiHAAAOhHjAADQyfjeA8DmzJk8OSvmz+89\nBgDADmFlHAAAOhHjAADQiRgHAIBOxDgAAHQixgEAoBMxDgAAnYhxAADoRIwDAEAnYhwAADoR4wAA\n0IkYBwCATsQ4AAB0IsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ9Va6z0DbFLVAS05rfcYAGyj1hb2HgFG\nVVWtbK3N3dJ2VsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ2IcAAA6EeMAANCJGAcAgE7EOAAAdLLFGK+q\nVlVf2OD++Kq6t6q+OYzXPjj43ylV9doNHp9bVedv7dDDUVWnVNXZW9jmjVX1ycHt91XVL6rq2Rs8\n/+AGtx+tqhuq6vtVdV1VHbPjpgcAYFcwnJXxh5JMq6qJg/svTfLTER5nSpL1Md5aW9Fae8cI9zEi\nrbVLW2vnjvBl9yU5YxPPPdxam9laOzLJOUn+ZpsGBABglzfcy1T+R5KTB7dfk+RLjz8xWFE+c4P7\nN1fVlCe9/twkvz1YWX53Vc1/fGV98PpFVbWsqv65qt6xwb7+YrC/m6vqXYPHplTVLVX1ucHjF1XV\nCVX1napaXVVHDbbbcNX7FVX1vaq6vqqWVtVzNvE+FyX5w6raZwu/Hk9P8rMtbAMAAJs13Bj/+yR/\nVFV7JJmR5HsjPM7ZSa4crCz/7UaePyzJiUmOSrKwqiZU1Zwkb0ry75O8IMlbqmrWYPvnJ/n4YJbD\nMrTq/sIkZyb5y43s/6okL2itzRq8l/+wiTkfzFCQv3Mjz00c/GPiliSfS/LXW3jPAACwWeOHs1Fr\n7cbBavdrkly2A+b4Vmvtl0l+WVX3JHlOhuL6a621h5Kkqv4hyW8nuTTJj1trNw0e/0GSb7fWWlXd\nlKFLYp7swCQXV9X+SZ6W5MebmeX8JDdU1Uee9PjDrbWZg2MeneTzVTWttda27i0DALCrG8mnqVya\n5MPZ4BKVgXVP2s8eWzHHLze4/WiG/pFQw9z+sQ3uP5aN/wPjE0k+2VqbnuS0zc3YWluTZHGS0zez\nzfIk+yV51mZmBACAzRpJjC9K8oHHV6Q3cEeS2UlSVbOTTN3Ia9cmmTzC2a5I8jtVNamq9kzyu0mu\nHOE+HveM/N9vOn3DMLb/aIaifaNfOaiqw5LsluT+rZwHAACGH+Ottbtaax/fyFOXJNmnqm5I8tYk\nt25kmxuTrBt8LOC7h3m865JcmOSaDF2j/rnW2vXDnfdJ3pfkK1V1ZYY+MWVLx74vydeS7L7Bw49f\nM35DkouTvKG19uhWzgMAACmXPLMzqzqgDX2RAoCxrLWFvUeAUVVVK1trc7e0nZ/ACQAAnYhxAADo\nRIwDAEAnYhwAADoR4wAA0IkYBwCATsQ4AAB0IsYBAKATMQ4AAJ2IcQAA6ESMAwBAJ2IcAAA6EeMA\nANCJGAcYGMpkAAAFKUlEQVQAgE7EOAAAdDK+9wCwOXPmHJAVKxb2HgMAYIewMg4AAJ2IcQAA6ESM\nAwBAJ2IcAAA6EeMAANCJGAcAgE7EOAAAdCLGAQCgEzEOAACdiHEAAOhEjAMAQCdiHAAAOhHjAADQ\niRgHAIBOxDgAAHQixgEAoBMxDgAAnYhxAADoRIwDAEAnYhwAADoR4wAA0IkYBwCATsQ4AAB0Uq21\n3jPAJlXV2iQ/6j0Hw7Jfkvt6D8GwOFdjh3M1djhXY8donauDWmvP2tJG40dhENgWP2qtze09BFtW\nVSucq7HBuRo7nKuxw7kaO3a2c+UyFQAA6ESMAwBAJ2Kcnd1neg/AsDlXY4dzNXY4V2OHczV27FTn\nyjdwAgBAJ1bGAQCgEzEOAACdiHG6q6qXVdWPquq2qjp7I8/vXlUXD57/XlVNGf0pSYZ1rv6iqn5Y\nVTdW1ber6qAec7Llc7XBdn9QVa2qdpqP+drVDOdcVdWrB7+3flBVi0d7RoYM48/A36yqy6vq+sGf\ngy/vMSdJVS2qqnuq6uZNPF9Vdf7gXN5YVbNHe8bHiXG6qqrdkvxdkpOS/FaS11TVbz1psz9L8rPW\n2vOT/G2S/zy6U5IM+1xdn2Rua21Gkq8m+f9Gd0qSYZ+rVNXkJO9I8r3RnZDHDedcVdXBSc5Jcmxr\n7Ygk7xr1QRnu76v/lOTLrbVZSf4oyQWjOyUbuDDJyzbz/ElJDh78d2qST43CTBslxuntqCS3tdb+\nubX2b0n+Pskrn7TNK5P8t8HtryZ5SVXVKM7IkC2eq9ba5a21XwzuXp3kwFGekSHD+X2VJH+doX8w\nPTKaw/EEwzlXb0nyd621nyVJa+2eUZ6RIcM5Vy3J0we3n5Hk7lGcjw201q5I8r83s8krk3y+Dbk6\nyd5Vtf/oTPdEYpzefiPJTza4f9fgsY1u01pbl+SBJPuOynRsaDjnakN/luR/7NCJ2JQtnquqmpXk\nua21b47mYDzFcH5fHZLkkKr6TlVdXVWbW+1jxxnOuXpfktdX1V1JLkvy9tEZja0w0r/TdpjxPQ4K\nG9jYCveTP29zONuw4w37PFTV65PMTfKiHToRm7LZc1VV4zJ0ydcbR2sgNmk4v6/GZ+hL6fMz9NWm\nK6tqWmttzQ6ejScazrl6TZILW2sfqaqjk3xhcK4e2/HjMUI7TVtYGae3u5I8d4P7B+apX9Zbv01V\njc/Ql/4296UndozhnKtU1QlJ/mOSU1prvxyl2XiiLZ2ryUmmJVlWVXckeUGSS30TZxfD/TPwG621\nX7XWfpzkRxmKc0bXcM7VnyX5cpK01pYn2SPJfqMyHSM1rL/TRoMYp7drkxxcVVOr6mkZ+oaXS5+0\nzaVJ3jC4/QdJ/lfz06p62OK5Glz68F8yFOKua+1ns+eqtfZAa22/1tqU1tqUDF3ff0prbUWfcXdp\nw/kz8OtJjk+SqtovQ5et/POoTkkyvHN1Z5KXJElVHZ6hGL93VKdkuC5N8ieDT1V5QZIHWmv/f49B\nXKZCV621dVX1/yb5pyS7JVnUWvtBVX0gyYrW2qVJ/muGvtR3W4ZWxP+o38S7rmGeq/OS7JXkK4Pv\nsb2ztXZKt6F3UcM8V+wEhnmu/inJgqr6YZJHk5zVWru/39S7pmGeqzOSfLaq3p2hSx7eaPGoj6r6\nUoYu7dpvcA3/wiQTkqS19ukMXdP/8iS3JflFkjf1mTQp/x8BAIA+XKYCAACdiHEAAOhEjAMAQCdi\nHAAAOhHjAADQiRgHAIBOxDgAAHTyfwDmwEyvCmlNWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x736ed6ec18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make some plots\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
