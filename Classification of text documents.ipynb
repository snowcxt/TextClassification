{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print classifier result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf, name):\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "    \n",
    "    joblib.dump(clf, 'models/' + name + '.pkl') \n",
    "    \n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "        print()\n",
    "    \n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,\n",
    "                                        target_names=target_names))\n",
    "\n",
    "\n",
    "#     print(\"confusion matrix:\")\n",
    "#     print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    results.append([clf_descr, score, train_time, test_time])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training & testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 22.055MB (training set)\n",
      "7532 documents - 13.801MB (test set)\n",
      "\n",
      "categories:  ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "categories = None\n",
    "#remove = ('headers', 'footers', 'quotes')\n",
    "remove = ()\n",
    "    \n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "target_names = data_train.target_names\n",
    "joblib.dump(target_names, 'categories.pkl') \n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print()\n",
    "\n",
    "print(\"categories: \", target_names)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 11314, n_features: 129791\n",
      "\n",
      "n_samples: 7532, n_features: 129791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.136s\n",
      "test time:  0.037s\n",
      "accuracy:   0.837\n",
      "dimensionality: 129791\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.83      0.80      0.81       319\n",
      "           comp.graphics       0.68      0.74      0.71       389\n",
      " comp.os.ms-windows.misc       0.77      0.59      0.67       394\n",
      "comp.sys.ibm.pc.hardware       0.66      0.77      0.71       392\n",
      "   comp.sys.mac.hardware       0.83      0.84      0.84       385\n",
      "          comp.windows.x       0.82      0.79      0.81       395\n",
      "            misc.forsale       0.81      0.79      0.80       390\n",
      "               rec.autos       0.90      0.91      0.91       396\n",
      "         rec.motorcycles       0.94      0.96      0.95       398\n",
      "      rec.sport.baseball       0.96      0.94      0.95       397\n",
      "        rec.sport.hockey       0.95      0.98      0.96       399\n",
      "               sci.crypt       0.87      0.93      0.90       396\n",
      "         sci.electronics       0.79      0.77      0.78       393\n",
      "                 sci.med       0.90      0.84      0.87       396\n",
      "               sci.space       0.87      0.92      0.89       394\n",
      "  soc.religion.christian       0.85      0.94      0.90       398\n",
      "      talk.politics.guns       0.76      0.91      0.83       364\n",
      "   talk.politics.mideast       0.97      0.94      0.96       376\n",
      "      talk.politics.misc       0.77      0.63      0.69       310\n",
      "      talk.religion.misc       0.77      0.63      0.69       251\n",
      "\n",
      "             avg / total       0.84      0.84      0.84      7532\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "benchmark(MultinomialNB(alpha=.01), 'MultinomialNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes\n",
    "BernoulliNB might perform better on some datasets, especially those with shorter documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.156s\n",
      "test time:  0.124s\n",
      "accuracy:   0.771\n",
      "dimensionality: 129791\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.75      0.83      0.79       319\n",
      "           comp.graphics       0.55      0.74      0.63       389\n",
      " comp.os.ms-windows.misc       0.79      0.07      0.13       394\n",
      "comp.sys.ibm.pc.hardware       0.51      0.76      0.61       392\n",
      "   comp.sys.mac.hardware       0.66      0.83      0.74       385\n",
      "          comp.windows.x       0.80      0.71      0.75       395\n",
      "            misc.forsale       0.56      0.88      0.68       390\n",
      "               rec.autos       0.87      0.87      0.87       396\n",
      "         rec.motorcycles       0.90      0.94      0.92       398\n",
      "      rec.sport.baseball       0.96      0.90      0.93       397\n",
      "        rec.sport.hockey       0.97      0.92      0.95       399\n",
      "               sci.crypt       0.88      0.85      0.86       396\n",
      "         sci.electronics       0.70      0.73      0.72       393\n",
      "                 sci.med       0.91      0.71      0.80       396\n",
      "               sci.space       0.87      0.83      0.85       394\n",
      "  soc.religion.christian       0.90      0.89      0.90       398\n",
      "      talk.politics.guns       0.83      0.84      0.83       364\n",
      "   talk.politics.mideast       0.98      0.83      0.90       376\n",
      "      talk.politics.misc       0.74      0.59      0.66       310\n",
      "      talk.religion.misc       0.69      0.63      0.66       251\n",
      "\n",
      "             avg / total       0.80      0.77      0.76      7532\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "benchmark(BernoulliNB(alpha=.01), 'BernoulliNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 7.105s\n",
      "test time:  0.035s\n",
      "accuracy:   0.842\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.78      0.78      0.78       319\n",
      "           comp.graphics       0.74      0.78      0.76       389\n",
      " comp.os.ms-windows.misc       0.79      0.78      0.79       394\n",
      "comp.sys.ibm.pc.hardware       0.72      0.75      0.74       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.86      0.76      0.81       395\n",
      "            misc.forsale       0.83      0.89      0.86       390\n",
      "               rec.autos       0.90      0.90      0.90       396\n",
      "         rec.motorcycles       0.94      0.94      0.94       398\n",
      "      rec.sport.baseball       0.93      0.93      0.93       397\n",
      "        rec.sport.hockey       0.96      0.97      0.96       399\n",
      "               sci.crypt       0.92      0.93      0.93       396\n",
      "         sci.electronics       0.78      0.75      0.76       393\n",
      "                 sci.med       0.88      0.87      0.88       396\n",
      "               sci.space       0.88      0.93      0.91       394\n",
      "  soc.religion.christian       0.85      0.92      0.89       398\n",
      "      talk.politics.guns       0.72      0.92      0.81       364\n",
      "   talk.politics.mideast       0.96      0.86      0.91       376\n",
      "      talk.politics.misc       0.82      0.59      0.68       310\n",
      "      talk.religion.misc       0.71      0.59      0.64       251\n",
      "\n",
      "             avg / total       0.84      0.84      0.84      7532\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))]), 'LinearSVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd9f30f84a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make some plots\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
